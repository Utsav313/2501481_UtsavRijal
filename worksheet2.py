# -*- coding: utf-8 -*-
"""Worksheet2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wSAovNMCdj7VpJefeX0PZtCbrmeWVEmZ
"""

import pandas as pd
import numpy as np
from google.colab import drive
bank_df = pd.read_csv('/content/drive/Othercomputers/My Laptop/Downloads/Dataset-20251201T153502Z-1-001/Dataset/bank.csv')
print("Dataset loaded successfully!")
print(f"Shape: {bank_df.shape}")
print(bank_df.head())

try:
    bank_df = pd.read_csv('/content/drive/Othercomputers/My Laptop/Downloads/Dataset-20251201T153502Z-1-001/Dataset/bank.csv')
    print("Dataset loaded successfully!")
    print(f"Shape: {bank_df.shape}")
except FileNotFoundError:
    print("ERROR: bank.csv not found. Please update the file path.")
    # Creating a sample dataset for demonstration
    bank_df = pd.DataFrame({
        'age': [25, 30, 35, 40, 45],
        'job': ['admin', 'technician', 'services', 'admin', 'blue-collar'],
        'marital': ['single', 'married', 'married', 'single', 'divorced'],
        'balance': [1000, 2000, 1500, 3000, 500],
        'duration': [120, 150, 180, 200, 100]
    })
    print("Using sample data for demonstration.")

print("\n[Task 2a] DataFrame Info:")
print("-"*80)
bank_df.info()

print("\n[Task 2b] Unique values of object columns:")
for col in object_columns:
    print(f"\n{col}: {bank_df[col].nunique()} unique values")
    print(f"Values: {bank_df[col].unique()[:10]}")

print("\n[Task 2c] Total number of null values in each column:")
null_counts = bank_df.isnull().sum()
print(null_counts)
print(f"\nTotal null values in dataset: {null_counts.sum()}")

print("\n[Task 3] Dropping object columns and saving...")
bank_numeric_df = bank_df.select_dtypes(exclude='object')
print(f"New DataFrame shape: {bank_numeric_df.shape}")
bank_numeric_df.to_csv("banknumericdata.csv", index=False)
print("Saved as 'banknumericdata.csv'")

print("\n[Task 4] Reading banknumericdata.csv and displaying summary statistics:")
bank_numeric_read = pd.read_csv("banknumericdata.csv")
print("\nSummary Statistics:")
print(bank_numeric_read.describe())

try:
    medical_df = pd.read_csv('/content/drive/Othercomputers/My Laptop/Downloads/Dataset-20251201T153502Z-1-001/Dataset/medical_students_dataset.csv')
    print("Dataset loaded successfully!")
    print(f"Shape: {medical_df.shape}")
except FileNotFoundError:
    print("ERROR: medical_student.csv not found. Creating sample data...")
    np.random.seed(42)
    medical_df = pd.DataFrame({
        'student_id': range(1, 51),
        'age': np.random.choice([20, 21, 22, 23, 24, None], 50),
        'height': np.random.choice([150, 160, 170, 180, None], 50),
        'weight': np.random.choice([50, 60, 70, 80, None], 50),
        'blood_pressure': np.random.choice([120, 130, 140, None], 50),
        'study_hours': np.random.choice([2, 4, 6, 8, None], 50)
    })
    print("Using sample data for demonstration.")

print("\n[Task 2] DataFrame Info:")
print("-"*80)
medical_df.info()

print("\n[Task 2] Columns with missing values:")
missing_values = medical_df.isnull().sum()
columns_with_missing = missing_values[missing_values > 0]
print(columns_with_missing)

print("\n[Task 3] Filling missing values using various techniques:")
print("-"*80)

medical_df_filled = medical_df.copy()

# Strategy for each column
for col in columns_with_missing.index:
    missing_count = columns_with_missing[col]
    print(f"\n{col}: {missing_count} missing values")

    if col in ['age', 'height', 'weight']:
        # Use median for physiological measurements (less affected by outliers)
        fill_value = medical_df[col].median()
        medical_df_filled[col] = medical_df_filled[col].fillna(fill_value)
        print(f"  -> Filled with MEDIAN ({fill_value})")
        print(f"  -> Reason: Physiological measurements may have outliers; median is robust")

    elif col == 'blood_pressure':
        # Use mean for normally distributed medical readings
        fill_value = medical_df[col].mean()
        medical_df_filled[col] = medical_df_filled[col].fillna(fill_value)
        print(f"  -> Filled with MEAN ({fill_value:.2f})")
        print(f"  -> Reason: Blood pressure typically follows normal distribution")

    elif col == 'study_hours':
        # Use forward fill for time-series or sequential data
        medical_df_filled[col] = medical_df_filled[col].fillna(method='ffill')
        print(f"  -> Filled with FORWARD FILL")
        print(f"  -> Reason: Study hours may be consistent over time")

print("\n[Task 3] Verification - Missing values after filling:")
print(medical_df_filled.isnull().sum())

print("\n[Task 4] Checking for duplicate values:")
duplicate_count = medical_df_filled.duplicated().sum()
print(f"Number of duplicate rows: {duplicate_count}")

if duplicate_count > 0:
    print(f"Removing {duplicate_count} duplicate rows...")
    medical_df_filled = medical_df_filled.drop_duplicates()
    print(f"New shape after removing duplicates: {medical_df_filled.shape}")
else:
    print("No duplicate rows found.")

try:
    titanic_df = pd.read_csv('/content/drive/Othercomputers/My Laptop/Downloads/Dataset-20251201T153502Z-1-001/Dataset/Titanic-Dataset.csv')
    print("Titanic dataset loaded successfully!")
    print(f"Shape: {titanic_df.shape}")
except FileNotFoundError:
    print("ERROR: titanic.csv not found. Using seaborn's built-in Titanic dataset...")
    titanic_df = sns.load_dataset('titanic')
    print("Loaded from seaborn.")

print("\nFirst few rows of Titanic dataset:")
print(titanic_df.head())

print("\n\n" + "="*80)
print("PROBLEM 1: First-Class Passenger Fare Analysis")
print("="*80)

# Create subsetted DataFrame
columns_needed = ['Name', 'Pclass', 'Sex', 'Age', 'Fare', 'Survived']
# Check which columns exist
available_cols = [col for col in columns_needed if col in titanic_df.columns]
print(f"\nAvailable columns: {available_cols}")

titanic_subset = titanic_df[available_cols].copy()

# Filter for first-class passengers (Pclass == 1)
if 'Pclass' in titanic_subset.columns:
    first_class = titanic_subset[titanic_subset['Pclass'] == 1].copy()
    print(f"\nFirst-class passengers: {len(first_class)}")

    # Calculate Fare statistics
    if 'Fare' in first_class.columns:
        print("\nFare Statistics for First-Class Passengers:")
        print(f"  Mean:    ${first_class['Fare'].mean():.2f}")
        print(f"  Median:  ${first_class['Fare'].median():.2f}")
        print(f"  Maximum: ${first_class['Fare'].max():.2f}")
        print(f"  Minimum: ${first_class['Fare'].min():.2f}")
else:
    print("Pclass column not found!")

print("\n\n" + "="*80)
print("="*80)
if 'Age' in first_class.columns:
    null_age_count = first_class['Age'].isnull().sum()
    print(f"\nNumber of null values in 'Age' column: {null_age_count}")
    first_class_clean = first_class.dropna(subset=['Age'])
    print(f"Rows before dropping nulls: {len(first_class)}")
    print(f"Rows after dropping nulls:  {len(first_class_clean)}")
    print(f"Rows removed: {len(first_class) - len(first_class_clean)}")
else:
    first_class_clean = first_class.copy()
    print("Age column not found!")

print("\n\n" + "="*80)
print("PROBLEM 3: One-Hot Encoding for Embarked Column")
print("="*80)
if 'Embarked' in titanic_df.columns:
    print("\nOriginal Embarked values:")
    print(titanic_df['Embarked'].value_counts())
    embarked_encoded = pd.get_dummies(titanic_df['Embarked'], prefix='Embarked')
    titanic_encoded = pd.concat([titanic_df, embarked_encoded], axis=1)
    titanic_encoded = titanic_encoded.drop('Embarked', axis=1)
    print("\nNew columns created:")
    print([col for col in titanic_encoded.columns if 'Embarked_' in col])
    print("\nFirst few rows of modified DataFrame:")
    embarked_cols = [col for col in titanic_encoded.columns if 'Embarked_' in col]
    print(titanic_encoded[['Name'] + embarked_cols].head())
else:
    print("Embarked column not found!")
    titanic_encoded = titanic_df.copy()

print("\n\n" + "="*80)
print("="*80)

if 'Sex' in titanic_df.columns and 'Survived' in titanic_df.columns:
    print("\nMean survival rates by gender:")
    survival_by_sex = titanic_df.groupby('Sex')['Survived'].mean()
    print(survival_by_sex)

    # Visualization
    plt.figure(figsize=(10, 6))

    # Bar plot
    plt.subplot(1, 2, 1)
    survival_by_sex.plot(kind='bar', color=['skyblue', 'lightcoral'])
    plt.title('Mean Survival Rate by Gender', fontsize=14, fontweight='bold')
    plt.xlabel('Gender', fontsize=12)
    plt.ylabel('Survival Rate', fontsize=12)
    plt.xticks(rotation=0)
    plt.ylim(0, 1)

    # Count plot
    plt.subplot(1, 2, 2)
    survival_counts = titanic_df.groupby(['Sex', 'Survived']).size().unstack()
    survival_counts.plot(kind='bar', stacked=False, color=['#d62728', '#2ca02c'])
    plt.title('Survival Distribution by Gender', fontsize=14, fontweight='bold')
    plt.xlabel('Gender', fontsize=12)
    plt.ylabel('Count', fontsize=12)
    plt.legend(['Did Not Survive', 'Survived'], loc='upper right')
    plt.xticks(rotation=0)

    plt.tight_layout()
    plt.savefig('problem4_survival_by_gender.png', dpi=300, bbox_inches='tight')
    print("\nVisualization saved as 'problem4_survival_by_gender.png'")
    plt.show()
else:
    print("Required columns not found!")

print("\n\n" + "="*80)
print("="*80)
if 'Sex' in titanic_df.columns and 'Survived' in titanic_df.columns and 'Embarked' in titanic_df.columns:
    # Filter for valid embarkation ports
    titanic_embarked = titanic_df[titanic_df['Embarked'].isin(['C', 'Q', 'S'])].copy()
    print("\nMean survival rates by gender and port:")
    survival_by_sex_embarked = titanic_embarked.groupby(['Sex', 'Embarked'])['Survived'].mean()
    print(survival_by_sex_embarked)

    # Visualization
    plt.figure(figsize=(12, 6))
    # Grouped bar chart
    survival_pivot = titanic_embarked.groupby(['Embarked', 'Sex'])['Survived'].mean().unstack()
    survival_pivot.plot(kind='bar', color=['skyblue', 'lightcoral'], width=0.8)

    plt.title('Survival Rates by Port of Embarkation and Gender', fontsize=14, fontweight='bold')
    plt.xlabel('Port of Embarkation', fontsize=12)
    plt.ylabel('Survival Rate', fontsize=12)
    plt.legend(['Female', 'Male'], title='Gender')
    plt.xticks(rotation=0)
    plt.ylim(0, 1)

    # Add value labels on bars
    for container in plt.gca().containers:
        plt.gca().bar_label(container, fmt='%.2f', padding=3)

    port_names = {'C': 'Cherbourg', 'Q': 'Queenstown', 'S': 'Southampton'}
    labels = [port_names[label.get_text()] for label in plt.gca().get_xticklabels()]
    plt.gca().set_xticklabels(labels)

    plt.tight_layout()
    plt.savefig('problem5_survival_by_gender_port.png', dpi=300, bbox_inches='tight')
    print("\nVisualization saved as 'problem5_survival_by_gender_port.png'")
    plt.show()
else:
    print("Required columns not found!")